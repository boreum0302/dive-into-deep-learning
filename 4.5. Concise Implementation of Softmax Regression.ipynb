{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39fad5f0-cda8-43fa-b667-0a5473e2169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c5824a-d4c6-4576-a160-9a8f91177561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6aa42-ebca-428e-ac32-d2afc5ef96af",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fce7f16-d32e-4316-9707-5cadc9a1cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((32, 32)),  # upscale\n",
    "                            transforms.ToTensor()])\n",
    "\n",
    "data_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=trans, download=False \n",
    ")\n",
    "data_val = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, transform=trans, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0e9173-ef66-44d4-857f-6785fecf6e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed68f685-63b0-4b87-9b05-536712956500",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad5f39c-d049-4aac-af37-90cc8b06a5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 32, 32])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d64a29-b0c0-48b7-9bed-4345417aeae3",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1e7539-b792-4fea-a84b-4a2e3c61360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxRegression(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_inputs, num_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53299312-9851-4f00-86fb-85d30a7a4be1",
   "metadata": {},
   "source": [
    "## **Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacf16ba-ad11-4c0d-99eb-38ff9b87a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    # y_hat: (B, q)\n",
    "    # y: (B)\n",
    "    return F.cross_entropy(y_hat, y, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5732ad89-22cf-474c-a903-844ad659676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    # y_hat: (B, q)\n",
    "    # y: (B)\n",
    "    preds = y_hat.argmax(axis=1).type(y.dtype)  # (B)\n",
    "    compare = (preds == y).type(torch.float32)  # (B)\n",
    "    return compare.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313da8d-2627-46a3-9d58-ca27fb2344cc",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d4472c-d455-437e-89ce-e2814cb1be4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftmaxRegression(\n",
       "  (net): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SoftmaxRegression(num_inputs=1*32*32, num_outputs=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "961faaa5-47e0-4c20-b8ea-63c68e7d9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1ee22b-f7b0-4037-a16c-53ac85b34b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=00 | train_loss=0.7803 | val_loss=0.6188 | val_acc=0.7910\n",
      "epoch=01 | train_loss=0.5742 | val_loss=0.5590 | val_acc=0.8101\n",
      "epoch=02 | train_loss=0.5286 | val_loss=0.5361 | val_acc=0.8173\n",
      "epoch=03 | train_loss=0.5051 | val_loss=0.5334 | val_acc=0.8118\n",
      "epoch=04 | train_loss=0.4902 | val_loss=0.5260 | val_acc=0.8228\n",
      "epoch=05 | train_loss=0.4790 | val_loss=0.6973 | val_acc=0.7680\n",
      "epoch=06 | train_loss=0.4706 | val_loss=0.4898 | val_acc=0.8293\n",
      "epoch=07 | train_loss=0.4634 | val_loss=0.4820 | val_acc=0.8341\n",
      "epoch=08 | train_loss=0.4579 | val_loss=0.4789 | val_acc=0.8341\n",
      "epoch=09 | train_loss=0.4524 | val_loss=0.4901 | val_acc=0.8313\n",
      "CPU times: total: 8min 11s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_epochs = 10\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    \n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    num_val_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            y_hat = model(X)\n",
    "            loss = cross_entropy(y_hat, y)\n",
    "            val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "            val_acc += accuracy(y_hat, y)\n",
    "\n",
    "    print(f'epoch={i:02d} | train_loss={train_loss/num_train_batches:.4f} | val_loss={val_loss/num_val_batches:.4f} | val_acc={val_acc/num_val_batches:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
