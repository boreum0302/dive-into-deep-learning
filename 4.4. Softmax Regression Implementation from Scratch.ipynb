{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71db8815-d9b1-4576-80ac-59cdbba0a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd735ef-0bcf-4340-a185-541407e86f9e",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c6612e-11e5-42a6-b10f-d8d0c3b5fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((32, 32)),  # upscale\n",
    "                            transforms.ToTensor()])\n",
    "\n",
    "data_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=trans, download=False \n",
    ")\n",
    "data_val = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, transform=trans, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0988bb42-1d49-44bf-8780-6d34b9a6b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432402ea-9d97-40bb-a844-0e623ca6d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844bf2a1-2e44-40dc-a9e8-0cd1aba99198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 32, 32])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd577e-c218-48f7-b8c8-e2cfb4362a64",
   "metadata": {},
   "source": [
    "## **Softmax Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62414c2-7bc5-4f5b-a1cc-4abf4fe1f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[1.0, 2, 3,], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ee2e56-b726-4d01-84f5-20d0bbcc26cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e45e796-bde4-4215-a701-027cd372ce5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 7., 9.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=0, keepdims=True)  # shape: (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c727aecc-5a1e-4605-b886-b6d2c5151672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.],\n",
       "        [15.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum(axis=1, keepdims=True)  # shape: (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8fa0ae-b297-4848-b6e3-c12b1015efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):  # X.shape = (n, d)\n",
    "    X_exp = torch.exp(X)  # elementwise\n",
    "    partition = X_exp.sum(1, keepdims=True)  # shape: (n, 1)\n",
    "    return X_exp / partition  # shape: (n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17923a0c-cd8c-45be-b349-88478b3f7b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(X)  # each row sums up to 1, as is required for a probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd75b15-43cc-4a28-a9ed-024065be57a7",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1723cb-bcb5-485d-8a15-920d2d299417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O = XW + b\n",
    "# d = num_inputs\n",
    "# q = num_outputs\n",
    "# Y: (n, q)\n",
    "# X: (n, d)\n",
    "# W: (d, q)\n",
    "# b: (q)\n",
    "\n",
    "class SoftmaxRegressionScratch(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, sigma=0.01):\n",
    "        super().__init__()\n",
    "        self.W = torch.normal(0, sigma, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "        self.b = torch.zeros(num_outputs, requires_grad=True)\n",
    "\n",
    "    def forward(self, X):  # (B, c, h, w), d = c*h*w\n",
    "        X = X.reshape((-1, self.W.shape[0]))  # (-1, d) = (B, d)\n",
    "        return softmax(torch.matmul(X, self.W) + self.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3deba-9240-4e3f-8bfa-0208c052b574",
   "metadata": {},
   "source": [
    "## **Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f50da82-dbad-402f-815d-cb1d79adc2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    # y_hat: (B, q)\n",
    "    # y: (B)\n",
    "    # sum -y_i*log(y_hat_i)\n",
    "    return -torch.log(y_hat[list(range(y_hat.shape[0])), y]).mean()  # 정의는 sum()인데 batch_size로 나눠주려고 mean() 씀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50643860-9158-4c36-a9ef-b30a68bb0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    # y_hat: (B, q)\n",
    "    # y: (B)\n",
    "    preds = y_hat.argmax(axis=1).type(y.dtype)  # (B)\n",
    "    compare = (preds == y).type(torch.float32)  # (B)\n",
    "    return compare.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea177de0-8a53-4ab3-b07a-796acec2f242",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "751491bd-7df5-4e49-86c2-84de54961443",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "model = SoftmaxRegressionScratch(num_inputs=1*32*32, num_outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fb01ed9-aab3-4e16-a67c-aa949b62f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=[model.W, model.b], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25339cf9-0175-431f-af1f-f46d2dd3875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=00 | train_loss=0.7793 | val_loss=0.6283 | val_acc=0.7865\n",
      "epoch=01 | train_loss=0.5724 | val_loss=0.5629 | val_acc=0.8080\n",
      "epoch=02 | train_loss=0.5282 | val_loss=0.6079 | val_acc=0.7795\n",
      "epoch=03 | train_loss=0.5075 | val_loss=0.5775 | val_acc=0.7907\n",
      "epoch=04 | train_loss=0.4890 | val_loss=0.5138 | val_acc=0.8242\n",
      "epoch=05 | train_loss=0.4807 | val_loss=0.5384 | val_acc=0.8138\n",
      "epoch=06 | train_loss=0.4701 | val_loss=0.4974 | val_acc=0.8261\n",
      "epoch=07 | train_loss=0.4628 | val_loss=0.4929 | val_acc=0.8245\n",
      "epoch=08 | train_loss=0.4568 | val_loss=0.4860 | val_acc=0.8345\n",
      "epoch=09 | train_loss=0.4535 | val_loss=0.4859 | val_acc=0.8318\n",
      "CPU times: total: 8min 47s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_epochs = 10\n",
    "\n",
    "for i in range(max_epochs):\n",
    "    train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    \n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    num_val_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            y_hat = model(X)\n",
    "            loss = cross_entropy(y_hat, y)\n",
    "            val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "            val_acc += accuracy(y_hat, y)\n",
    "\n",
    "    print(f'epoch={i:02d} | train_loss={train_loss/num_train_batches:.4f} | val_loss={val_loss/num_val_batches:.4f} | val_acc={val_acc/num_val_batches:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
