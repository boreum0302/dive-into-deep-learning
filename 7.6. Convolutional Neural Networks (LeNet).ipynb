{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a8f5ba-4c0f-4022-9913-92786f06003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294caf6-95df-42fd-aed2-f065f4e3fc45",
   "metadata": {},
   "source": [
    "## **Data**\n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-iamges-idx3-ubyte.gz  \n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz  \n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-iamges-idx3-ubyte.gz  \n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-iamges-idx1-ubyte.gz  \n",
    "`{root}\\FashionMNIST\\raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e47df9-5d27-476e-9885-dc72a5fc81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((32, 32)),  # upscale\n",
    "                            transforms.ToTensor()])\n",
    "\n",
    "data_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=trans, download=False \n",
    ")\n",
    "data_val = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, transform=trans, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d4cb95-3682-4aa7-80ea-90109a2509dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b6a691-1940-46fd-956c-21bdf7602632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19d7caf5-49a4-4a79-8013-e664ee639ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "image, label = data_train[0]  # [image, label]\n",
    "print(image.shape) # (channel, height, weight)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6308cf-ae40-4cc0-ba24-9a2346a3dac9",
   "metadata": {},
   "source": [
    "## **LeNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a902b935-f1d4-4a26-9339-a0983fa32c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), padding=2), nn.Sigmoid(),\n",
    "            nn.AvgPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=1024, out_features=120), nn.Sigmoid(),\n",
    "            nn.Linear(in_features=120, out_features=84), nn.Sigmoid(),\n",
    "            nn.Linear(in_features=84, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):  # X.shape =(batch_size, channel, height, width)\n",
    "        return self.net(X)\n",
    "\n",
    "    def _myinit(self, module):\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "    def myinit(self):\n",
    "        self.apply(self._myinit)  # apply는 submodule을 재귀적으로 순회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530ceb8a-b413-4210-a936-15bd34f7b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model.myinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3005592-b01a-4020-a477-b91daf947169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 32, 32]             156\n",
      "           Sigmoid-2            [-1, 6, 32, 32]               0\n",
      "         AvgPool2d-3            [-1, 6, 16, 16]               0\n",
      "            Conv2d-4           [-1, 16, 16, 16]           2,416\n",
      "           Sigmoid-5           [-1, 16, 16, 16]               0\n",
      "         AvgPool2d-6             [-1, 16, 8, 8]               0\n",
      "           Flatten-7                 [-1, 1024]               0\n",
      "            Linear-8                  [-1, 120]         123,000\n",
      "           Sigmoid-9                  [-1, 120]               0\n",
      "           Linear-10                   [-1, 84]          10,164\n",
      "          Sigmoid-11                   [-1, 84]               0\n",
      "           Linear-12                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 136,586\n",
      "Trainable params: 136,586\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.19\n",
      "Params size (MB): 0.52\n",
      "Estimated Total Size (MB): 0.71\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size=(1, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72717f-b8f9-465c-b0a6-b3ba11f1961c",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3767a7fa-41b8-444e-aa4d-dc68dd7f8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf5348f-c10a-44e6-ba67-82b971ec7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "model.myinit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58a4c1d-1161-44e4-91c3-94eb874e0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8706590a-ae20-494b-8b36-180f63402e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    # y_hat: (B, q)\n",
    "    # y: (B)\n",
    "    preds = y_hat.argmax(axis=1).type(y.dtype)  # (B)\n",
    "    compare = (preds == y).type(torch.float32)  # (B)\n",
    "    return compare.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1030cf5-4fc3-433f-aadf-0e4a186f6ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0 | train_loss=2.3085 | val_loss=2.3074 | val_acc=0.1000\n",
      "epoch=1 | train_loss=2.3051 | val_loss=2.3006 | val_acc=0.1000\n",
      "epoch=2 | train_loss=2.1411 | val_loss=1.5327 | val_acc=0.5355\n",
      "epoch=3 | train_loss=1.2074 | val_loss=1.0390 | val_acc=0.6074\n",
      "epoch=4 | train_loss=0.9507 | val_loss=0.8705 | val_acc=0.6780\n",
      "epoch=5 | train_loss=0.8116 | val_loss=0.7860 | val_acc=0.6953\n",
      "epoch=6 | train_loss=0.7274 | val_loss=0.7085 | val_acc=0.7303\n",
      "epoch=7 | train_loss=0.6781 | val_loss=0.6940 | val_acc=0.7247\n",
      "epoch=8 | train_loss=0.6464 | val_loss=0.6641 | val_acc=0.7441\n",
      "epoch=9 | train_loss=0.6228 | val_loss=0.6250 | val_acc=0.7668\n",
      "CPU times: total: 26min 37s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    for X, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        num_val_batches = 0\n",
    "        val_acc = 0\n",
    "        total = 0\n",
    "        for X, y in val_loader:\n",
    "            y_hat = model(X)\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "            val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "            val_acc += accuracy(y_hat, y)\n",
    "            total += y.numel()\n",
    "        \n",
    "    print(f'epoch={i} | train_loss={train_loss/num_train_batches:.4f} | val_loss={val_loss/num_val_batches:.4f} | val_acc={val_acc/total:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
