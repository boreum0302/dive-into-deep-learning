{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "091b0120-ab9d-4eb0-a5e1-ee72be47b3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345df584-be68-420f-9119-59770d6c04b9",
   "metadata": {},
   "source": [
    "## **Data**\n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-iamges-idx3-ubyte.gz  \n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz  \n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-iamges-idx3-ubyte.gz  \n",
    "http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-iamges-idx1-ubyte.gz  \n",
    "`{root}\\FashionMNIST\\raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6191fe06-5448-4d20-abc2-f04749af2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.Resize((224, 224)),  # upscale\n",
    "                            transforms.ToTensor()])\n",
    "\n",
    "data_train = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, transform=trans, download=False \n",
    ")\n",
    "data_val = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, transform=trans, download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf262f8-29f0-4ec1-9dc1-e3474d533da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91875da3-dc87-40a6-ae2b-6efa0665bffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c5cfb60-88ca-4a7a-8fea-3d6caa4ef557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "image, label = data_train[0]  # [image, label]\n",
    "print(image.shape) # (channel, height, weight)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9d019-b889-4890-9bbc-36bd56dac649",
   "metadata": {},
   "source": [
    "## **Alexnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0b102e-a45e-489c-a087-1847d1c8e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(out_features=4096), nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=4096), nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=4096, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):  # X.shape =(batch_size, channel, height, width)\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3b85c50-a7b9-4194-beca-f60ff12211d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model = Alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2307819f-540a-4473-9ff1-724b37c99eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 96, 54, 54]          11,712\n",
      "              ReLU-2           [-1, 96, 54, 54]               0\n",
      "         MaxPool2d-3           [-1, 96, 26, 26]               0\n",
      "            Conv2d-4          [-1, 256, 26, 26]         614,656\n",
      "              ReLU-5          [-1, 256, 26, 26]               0\n",
      "         MaxPool2d-6          [-1, 256, 12, 12]               0\n",
      "            Conv2d-7          [-1, 384, 12, 12]         885,120\n",
      "              ReLU-8          [-1, 384, 12, 12]               0\n",
      "            Conv2d-9          [-1, 384, 12, 12]       1,327,488\n",
      "             ReLU-10          [-1, 384, 12, 12]               0\n",
      "           Conv2d-11          [-1, 256, 12, 12]         884,992\n",
      "             ReLU-12          [-1, 256, 12, 12]               0\n",
      "        MaxPool2d-13            [-1, 256, 5, 5]               0\n",
      "          Flatten-14                 [-1, 6400]               0\n",
      "           Linear-15                 [-1, 4096]      26,218,496\n",
      "          Dropout-16                 [-1, 4096]               0\n",
      "           Linear-17                 [-1, 4096]      16,781,312\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 46,764,746\n",
      "Trainable params: 46,764,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 10.16\n",
      "Params size (MB): 178.39\n",
      "Estimated Total Size (MB): 188.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, input_size=(1, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ddd8c-6e5c-4e97-81d9-92c760ddfb8f",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fc92aa-ccfa-4801-a4a0-af54c21cf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691a1ac8-6c87-43fe-9e1e-3a8dc8cc478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7100bd60-3e16-450a-b74d-cf5508a8193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf529d3-4714-49b7-952e-fb4648b38c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    # y_hat: (B, q)\n",
    "    # y: (B)\n",
    "    preds = y_hat.argmax(axis=1).type(y.dtype)  # (B)\n",
    "    compare = (preds == y).type(torch.float32)  # (B)\n",
    "    return compare.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6301f-6495-482e-9367-7202013cba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    for b, (X, y) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(X)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "        if b % 10 == 0:\n",
    "            print(f'epoch={i} | batch={b} | train_loss={train_loss/num_train_batches:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        num_val_batches = 0\n",
    "        val_acc = 0\n",
    "        total = 0\n",
    "        for X, y in val_loader:\n",
    "            y_hat = model(X)\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "            val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "            val_acc += accuracy(y_hat, y)\n",
    "            total += y.numel()\n",
    "        \n",
    "    print(f'epoch={i} | train_loss={train_loss/num_train_batches:.4f} | val_loss={val_loss/num_val_batches:.4f} | val_acc={val_acc/total:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "d2l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
